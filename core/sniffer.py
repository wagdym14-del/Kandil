import asyncio
import websockets
import json
import logging
import time
import streamlit as st  # Ø§Ù„Ù…Ø³ØªØ´Ø¹Ø± Ø§Ù„Ø³Ø­Ø§Ø¨ÙŠ
from typing import Optional, List, Dict
from dataclasses import dataclass

# Ù†Ø¸Ø§Ù… ØªØ³Ø¬ÙŠÙ„ Ø¬Ù†Ø§Ø¦ÙŠ ÙØ§Ø¦Ù‚ Ø§Ù„Ø¯Ù‚Ø©
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("SovereignSniffer.Ultra")

@dataclass
class MarketEvent:
    signature: str
    timestamp: float
    event_type: str
    risk_level: int
    raw_logs: List[str]

class PumpSniffer:
    """
    [2026-02-03] Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„ÙØ§Ø¦Ù‚ Ù„Ø±ØµØ¯ Ø§Ù„Ø«ØºØ±Ø§Øª Ø§Ù„Ø³Ù„ÙˆÙƒÙŠØ© (Behavioral Gap Detector).
    Ù†Ø¸Ø§Ù… ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØªØ¯ÙÙ‚ Ø§Ù„Ù…ØªÙˆØ§Ø²ÙŠ (Parallel Stream Processing).
    ØªÙ… Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ ÙƒØ§Ù…Ù„ Ø§Ù„Ù‚Ø¯Ø±Ø§Øª Ø§Ù„Ø£ØµÙ„ÙŠØ© Ù…Ø¹ Ù…ÙŠØ²Ø© Ø§Ù„Ø±Ø¨Ø· Ø§Ù„Ø³Ø­Ø§Ø¨ÙŠ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ.
    """
    PROGRAM_ID = "6EF8rrecthR5DkZJbdz4P8hHKXY6yizQ2EtJhEqNpump"

    def __init__(self, wss_url: str = None, archiver=None, workers: int = 5):
        # [ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø±Ø¨Ø· Ø§Ù„Ø³Ø­Ø§Ø¨ÙŠ Ø§Ù„Ø¬ÙˆÙ‡Ø±ÙŠ]
        # Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ© Ø§Ù„Ù…Ø·Ù„Ù‚Ø© Ù„Ù„Ù‚Ø±Ø§Ø¡Ø© Ù…Ù† Secrets Ù„Ø¶Ù…Ø§Ù† Ø§Ù„Ø§ØªØµØ§Ù„ Ø§Ù„Ø³Ø­Ø§Ø¨ÙŠ
        try:
            self.wss_url = st.secrets.get("WSS_URL_PRIMARY") or wss_url
        except Exception:
            self.wss_url = wss_url
            
        self.archiver = archiver
        self.workers_count = workers
        self._queue = asyncio.Queue(maxsize=10000) 
        self.is_running = False
        self._performance_metrics = {"total_processed": 0, "dropped": 0}

    async def _subscribe(self, ws):
        """ÙˆØ¸ÙŠÙØ© Ø§Ù„Ø§Ø´ØªØ±Ø§Ùƒ Ø§Ù„Ø£ØµÙ„ÙŠØ© Ù„Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ø§ØªØµØ§Ù„"""
        subscribe_msg = {
            "jsonrpc": "2.0",
            "id": 1,
            "method": "logsSubscribe",
            "params": [
                {"mentions": [self.PROGRAM_ID]},
                {"commitment": "processed"}
            ]
        }
        await ws.send(json.dumps(subscribe_msg))
        logger.info(f"ðŸ“¡ [CONNECTED] Monitoring: {self.PROGRAM_ID[:8]}...")

    async def start_sniffing(self):
        """Ø¥Ø·Ù„Ø§Ù‚ Ø§Ù„Ø±Ø§Ø¯Ø§Ø± Ø¨Ù†Ø¸Ø§Ù… Ø®ÙˆØ§Ø¯Ù… Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…ØªØ¹Ø¯Ø¯Ø© (Worker Pool)"""
        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø±Ø§Ø¨Ø· Ù„Ø¶Ù…Ø§Ù† Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ù…Ø³Ø§ÙØ§Øª ØªØ¹ÙŠÙ‚ Ø§Ù„Ø§ØªØµØ§Ù„
        if self.wss_url:
            self.wss_url = self.wss_url.strip()

        if not self.wss_url:
            logger.error("âŒ [CRITICAL] WSS URL is missing! Check Streamlit Secrets.")
            return

        self.is_running = True
        logger.info(f"ðŸš€ [ULTRA] Initializing {self.workers_count} Processing Workers...")

        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¹Ù…Ø§Ù„ (Workers) - Ø§Ù„Ù‚ÙˆØ© Ø§Ù„Ø¶Ø§Ø±Ø¨Ø© Ù„Ù„Ù†Ø¸Ø§Ù…
        workers = [asyncio.create_task(self._worker_logic(i)) for i in range(self.workers_count)]

        while self.is_running:
            try:
                # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø§ØªØµØ§Ù„ ÙØ§Ø¦Ù‚Ø© Ø§Ù„Ø³Ø±Ø¹Ø© ÙƒÙ…Ø§ ÙÙŠ ÙƒÙˆØ¯Ùƒ Ø§Ù„Ø£ØµÙ„ÙŠ
                async with websockets.connect(
                    self.wss_url, 
                    ping_interval=None, 
                    compression=None,   
                    extra_headers={"User-Agent": "Sovereign-Engine-v1.0"}
                ) as ws:
                    await self._subscribe(ws)
                    
                    while self.is_running:
                        raw_msg = await ws.recv()
                        if self._queue.full():
                            self._performance_metrics["dropped"] += 1
                            self._queue.get_nowait() 
                        
                        await self._queue.put((raw_msg, time.time()))

            except Exception as e:
                logger.error(f"âš ï¸ [CRITICAL] Radar Connection Lost: {e}")
                await asyncio.sleep(0.5) 

    async def _worker_logic(self, worker_id: int):
        """Ù…Ù†Ø·Ù‚ Ø§Ù„Ø¹Ø§Ù…Ù„ Ø§Ù„Ø°ÙƒÙŠ: ØªØ­Ù„ÙŠÙ„ ÙØ§Ø¦Ù‚ Ø§Ù„Ø³Ø±Ø¹Ø© ÙˆÙÙƒ ØªØ´ÙÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        while self.is_running:
            try:
                raw_msg, arrival_time = await self._queue.get()
                data = json.loads(raw_msg)
                if "params" in data:
                    result = data["params"]["result"]["value"]
                    event = self._deep_parse(result)
                    
                    if event:
                        # Ø£Ø±Ø´ÙØ© ÙÙˆØ±ÙŠØ© Ù…Ø¹ Ø­Ø³Ø§Ø¨ Ø²Ù…Ù† Ø§Ù„ØªØ£Ø®ÙŠØ± (Latency)
                        latency = (time.time() - arrival_time) * 1000
                        await self.archiver.analyze_and_archive(
                            wallet=event.signature,
                            raw_data={"logs": event.raw_logs, "latency_ms": latency},
                            behavior_tag=event.event_type
                        )
                        self._performance_metrics["total_processed"] += 1
                
                self._queue.task_done()
            except Exception as e:
                logger.error(f"Worker-{worker_id} Error: {e}")

    def _deep_parse(self, result: dict) -> Optional[MarketEvent]:
        """Ø§Ù„Ù…Ø­Ù„Ù„ Ø§Ù„Ù‡ÙŠÙƒÙ„ÙŠ: ÙØ­Øµ Ø¨ØµÙ…Ø§Øª ØµÙ†Ø§Ø¹ Ø§Ù„Ø³ÙˆÙ‚ (Ù…Ù†Ø·Ù‚Ùƒ Ø§Ù„ÙØ§Ø¦Ù‚)"""
        logs = result.get("logs", [])
        sig = result.get("signature")
        logs_str = "|".join(logs)

        # Ø¨ØµÙ…Ø© 1: Ø§Ù„Ø¥Ø·Ù„Ø§Ù‚ Ø§Ù„ÙÙˆØ±ÙŠ (Bundle Launch)
        if "mintTo" in logs_str and "InitializeMint" in logs_str:
            return MarketEvent(sig, time.time(), "INSTANT_BUNDLE_LAUNCH", 90, logs)
        
        # Ø¨ØµÙ…Ø© 2: Ø¯Ø®ÙˆÙ„ Ø§Ù„Ù…Ø·ÙˆØ± Ø§Ù„Ø¢Ù…Ù†
        if "SetAuthority" in logs_str and "Trade" in logs_str:
            return MarketEvent(sig, time.time(), "SAFE_DEV_ENTRY", 20, logs)

        # Ø¨ØµÙ…Ø© 3: Ø§Ù„ØªØ¬Ù…ÙŠØ¹ Ø¹Ø§Ù„ÙŠ Ø§Ù„ØªØ±Ø¯Ø¯ (Bot Activity)
        if logs_str.count("Trade") > 10:
            return MarketEvent(sig, time.time(), "HIGH_FREQUENCY_ACCUMULATION", 60, logs)

        return None
